{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drcZacjAs_GF",
        "outputId": "4c998c45-1eff-4a78-f68e-bcaefcf919c6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "jJU0zll_pAsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "PATH = \"test_input\"  \n",
        "file_dir = sorted(os.listdir(PATH)) \n",
        "X_data = list()\n",
        "y_data = list()\n",
        "max_length = -1\n",
        "for file in file_dir:\n",
        "    loaded_file = np.load(PATH + \"/\" + file)\n",
        "    # if the file name ends with \"X.npy\"\n",
        "    if file.endswith(\"ans.npy\"):\n",
        "        y_data.append(loaded_file)\n",
        "    else:\n",
        "        X_data.append(loaded_file)\n",
        "    max_length = max_length if max_length>=loaded_file.shape[0] else loaded_file.shape[0]\n",
        "\n",
        "max_length += 1 # extra step to denote the end point of the song\n",
        "\n",
        "# add 0 to the end of each sample to make them the same length\n",
        "for i in range(len(X_data)):\n",
        "    X_data[i] = np.pad(X_data[i], ((0, max_length-X_data[i].shape[0]), (0, 0)), 'constant')\n",
        "for i in range(len(y_data)):\n",
        "    og_len = y_data[i].shape[0] # original length\n",
        "    y_data[i] = np.pad(y_data[i], ((0, max_length-y_data[i].shape[0]), (0, 0)), 'constant')\n",
        "    \n",
        "    # extend 2 index (start and end indicator)\n",
        "    denote_dim = np.zeros((max_length, 2))\n",
        "    denote_dim[og_len+1:, 1] = 1 # denote the end\n",
        "    y_data[i] = np.append(y_data[i], denote_dim, axis=0)\n",
        "\n",
        "start_point_index = 52\n",
        "end_point_index = 53\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "y_data = np.array(y_data) \n",
        "\n",
        "print(\"X_data shape: (train_size, max_length, input_size)\", X_data.shape)\n",
        "print(\"y_data shape: (train_size, max_length, n_pitch+2)\", y_data.shape)"
      ],
      "metadata": {
        "id": "2QzKqV1Wo_t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**\n",
        "Structure:\n",
        "* https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/ (major)\n",
        "* https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html (minor)\n",
        "\n",
        "Ref:\n",
        "* https://alvinntnu.github.io/python-notes/nlp/seq-to-seq-attention-addition.html\n",
        "* https://keras.io/api/layers/attention_layers/attention/\n",
        "* https://www.youtube.com/watch?v=B3uws4cLcFw"
      ],
      "metadata": {
        "id": "ysk_4cPxhPJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Parameter*"
      ],
      "metadata": {
        "id": "K5Woo5A3hKcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(X_data)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = train_size//BATCH_SIZE\n",
        "\n",
        "max_length = max_length # music piece length\n",
        "\n",
        "units = 1024 # hidden units\n",
        "\n",
        "start_point_index = start_point_index\n",
        "end_point_index = end_point_index\n",
        "\n",
        "n_pitch = 52\n",
        "\n",
        "input_size = 42\n",
        "target_size = n_pitch + 2 # n_pitch (52) + start,end (2)\n"
      ],
      "metadata": {
        "id": "4PffMiZsWkiJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Design*"
      ],
      "metadata": {
        "id": "-iNw1jKYqjil"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJzyG1vBXZiv"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import AdditiveAttention, Attention\n",
        "from keras.layers import Input, Concatenate, Dense, LSTM, Embedding, GRU\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, units, batch_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.units = units\n",
        "\n",
        "    # GRU Layer\n",
        "    # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n",
        "    # used for the linear transformation of the recurrent state\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Encoder network comprises an Embedding layer followed by a GRU layer\n",
        "  def call(self, x, hidden=None):\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, output_dim, units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.units = units\n",
        "    self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "    # Used for attention\n",
        "    self.attention = Attention(self.units) # or AdditiveAttention\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x reshape == (batch_size, 1, target_size)\n",
        "\n",
        "    # hidden shape == (batch_size, max_length)\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "\n",
        "    # context_vector shape == (batch_size, hidden_size)\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "   \n",
        "    context_vector, attention_weights = self.attention([tf.expand_dims(hidden,1), enc_output], return_attention_scores=True)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, target_size) --> (None, 1, 52)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, target_size + hidden_size) --> (None, 1, 1076)\n",
        "    x = tf.concat([context_vector, x], axis=-1)\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, 1, target_size)\n",
        "    x = tf.expand_dims(self.fc(output), 1)\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Encoder"
      ],
      "metadata": {
        "id": "bN67FwNrhSyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_batch = tf.random.uniform((BATCH_SIZE, max_length, input_size))\n",
        "example_target_batch = tf.random.uniform((BATCH_SIZE, max_length, target_size))"
      ],
      "metadata": {
        "id": "ukQgakzUYvUj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(input_size, units, BATCH_SIZE)\n",
        "\n",
        "sample_output, sample_hidden = encoder(example_input_batch) # can input none to use internal hidden RNN states\n",
        "# sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "\n",
        "print ('Encoder output shape: (batch size, max_length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "metadata": {
        "id": "q1OR0FO1YNpJ",
        "outputId": "907b6c38-cfff-42eb-db8b-99e4c3ff8400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, max_length, units) (64, 100, 1024)\n",
            "Encoder hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Attention"
      ],
      "metadata": {
        "id": "Yr66DB3EhUaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = Attention(10) # or AdditiveAttention\n",
        "attention_context, attention_weights = attention_layer([tf.expand_dims(sample_hidden,1), sample_output], return_attention_scores=True)\n",
        "\n",
        "print(\"Attention context shape: (batch size, 1 ,units) {}\".format(attention_context.shape))\n",
        "print(\"Attention weights shape: (batch_size, 1, max_length) {}\".format(attention_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMlEbQDRdA-a",
        "outputId": "78658074-93d6-4c0e-e71d-d1f7e119734f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention context shape: (batch size, 1 ,units) (64, 1, 1024)\n",
            "Attention weights shape: (batch_size, 1, max_length) (64, 1, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Decoder"
      ],
      "metadata": {
        "id": "qhFXAs4thXQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(target_size, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1, target_size)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, 1, target_size) {}'.format(sample_decoder_output.shape))"
      ],
      "metadata": {
        "id": "aeBgCWQwXItQ",
        "outputId": "6de6b5dd-e8a6-404e-ae99-0768869076ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, 1, target_size) (64, 1, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Build*"
      ],
      "metadata": {
        "id": "ScRpAGE1haN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "# Set up Encoder\n",
        "encoder_inputs = Input(shape=(max_length, input_size))  # process whole timestep at a time\n",
        "\n",
        "encoder = Encoder(input_size, units, BATCH_SIZE)\n",
        "encoder_outputs, states = encoder(encoder_inputs) # states := states RNN output\n",
        "\n",
        "# Set up Decoder\n",
        "decoder_inputs = Input(shape=(1, target_size)) # only process one timestep at a time\n",
        "\n",
        "decoder = Decoder(target_size, units, BATCH_SIZE)\n",
        "\n",
        "all_outputs = []\n",
        "inputs = decoder_inputs\n",
        "for _ in range(max_length):\n",
        "    # Run the decoder on one timestep\n",
        "    outputs, states, att_w = decoder(inputs, states, encoder_outputs)\n",
        "    \n",
        "    # Store the current prediction (we will concatenate all predictions later)\n",
        "    all_outputs.append(outputs)\n",
        "    # Reinject the outputs as inputs for the next loop iteration, as well as update the states\n",
        "    inputs = outputs\n",
        "    states = states\n",
        "\n",
        "# Concatenate all predictions\n",
        "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "\n",
        "# Define and compile model as previously\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "wKQ5qSuFN2rQ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Training*"
      ],
      "metadata": {
        "id": "7x03N4jlrUut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss_function(y_true, y_pred):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1* target_size)  # false if it is a padding time step\n",
        "    loss = tf.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    mask = tf.cast(mask, loss.dtype)\n",
        "    loss *= mask\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "def masked_accuracy(y_true, y_pred):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1* target_size)  # false if it is a padding time step\n",
        "    acc = tf.metrics.categorical_accuracy(y_true, y_pred)\n",
        "    mask = tf.cast(mask, acc.dtype)\n",
        "    acc *= mask\n",
        "    return tf.reduce_mean(acc)"
      ],
      "metadata": {
        "id": "Jqzuy9Z9rTRj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adamax',\n",
        "              loss=masked_loss_function,\n",
        "              metrics=masked_accuracy,\n",
        "              )"
      ],
      "metadata": {
        "id": "MJgftOzIvxtj"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = './checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "IEEFfGMtuSrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data = np.zeros((train_size, 1, target_size))\n",
        "decoder_input_data[:, 0, start_point_index] = 1 \n",
        "\n",
        "# Train model as previously\n",
        "model.fit([X_data, decoder_input_data], \n",
        "          y_data,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[model_checkpoint_callback],\n",
        "          )"
      ],
      "metadata": {
        "id": "oSF0QsUGfhf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_filepath)"
      ],
      "metadata": {
        "id": "2MpshhRNvlp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.plot(model.history.history['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "h54ALiKcp_EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Predict*"
      ],
      "metadata": {
        "id": "HMm2rfAgpnQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=2)"
      ],
      "metadata": {
        "id": "HOaI-3QOps_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Midi Format Output**"
      ],
      "metadata": {
        "id": "utf7XJS2phmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import midi_np_translation.output2midi as output2midi\n",
        "PATH = \"test_input\"\n",
        "# load np file\n",
        "test_file = np.load(PATH + \"/\" + \"4on6.mid.npy\")\n",
        "test_file_truth = np.load(PATH + \"/\" + \"4on6.mid.ans.npy\")\n",
        "output2midi.output_to_midi(bass_ndarr=test_file_truth, output_path=\"4on6_truth.mid\")\n",
        "test_result = model.predict(slice_per_step(test_file))\n",
        "test_result = np.argmax(test_result, axis=2)\n",
        "output2midi.output_to_midi(bass_ndarr=test_result, output_path=\"4on6_result.mid\")"
      ],
      "metadata": {
        "id": "4jIJZ9zbpgQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}